import streamlit as st
import openpyxl
import pandas as pd
from openpyxl.utils import get_column_letter
import io

# Function to check if a cell has light blue background (adjust RGB if needed)
def is_light_blue(cell):
    # Assuming light blue is 'FFD3D3D3' or similar; inspect actual file for RGB
    try:
        return cell.fill.fgColor.rgb == 'FFD3D3D3'
    except:
        return False

# Function to get merged range for a cell
def get_merged_range(sheet, cell):
    for merged_range in sheet.merged_cells.ranges:
        if cell.coordinate in merged_range:
            return merged_range
    return None

# Function to make header names unique by appending suffix if duplicates
def make_unique(headers_list):
    seen = {}
    unique_headers = []
    for header in headers_list:
        if header in seen:
            seen[header] += 1
            unique_headers.append(f"{header}_{seen[header]}")
        else:
            seen[header] = 0
            unique_headers.append(header)
    return unique_headers

# Function to check if a row is a parent (A has value, rest blank)
def is_parent_row_by_blanks(sheet, row, max_col):
    cell_a = sheet[f'A{row}']
    if not cell_a.value or not cell_a.value.strip():
        return False
    # Check if all other columns are blank
    for col in range(2, max_col + 1):  # Start from B (column 2)
        col_letter = get_column_letter(col)
        if sheet[f'{col_letter}{row}'].value:
            return False  # Found a non-blank cell
    return True

# Function to process the sheet and flatten it dynamically
def process_sheet(sheet):
    headers = [None] * sheet.max_column  # List for headers in column order (0-indexed)
    vertical_headings = []
    data_rows = []  # To store data for each vertical heading
    
    # Step 1: Process A1-A3 (combine and wrap text) - Keep as is
    a1_text = sheet['A1'].value or ""
    a2_text = sheet['A2'].value or ""
    a3_text = sheet['A3'].value or ""
    combined_a1 = f"{a1_text} {a2_text} {a3_text}".strip()
    headers[0] = combined_a1  # Column A is index 0
    
    # Dynamic Header Construction: Scan for merged cells and build hierarchies
    processed_cols = set()  # To avoid reprocessing merged columns
    for row in range(1, 4):  # Check rows 1-3 for headers
        for col in range(1, sheet.max_column + 1):
            col_letter = get_column_letter(col)
            cell = sheet[f'{col_letter}{row}']
            if col in processed_cols or cell.value in [None, 'Comments']:
                continue
            merged_range = get_merged_range(sheet, cell)
            if merged_range:
                # Parent header
                parent = cell.value or ""
                # Get child cells (next row in the merged columns)
                child_row = row + 1
                child_values = []
                for merged_col in range(merged_range.min_col, merged_range.max_col + 1):
                    merged_col_letter = get_column_letter(merged_col)
                    child_cell = sheet[f'{merged_col_letter}{child_row}']
                    if child_cell.value:
                        child_values.append(child_cell.value)
                    processed_cols.add(merged_col)
                
                # Build headers for each column in the merge
                for i, merged_col in enumerate(range(merged_range.min_col, merged_range.max_col + 1)):
                    if i < len(child_values):
                        headers[merged_col - 1] = f"{parent}_{child_values[i]}"  # 0-indexed
                    else:
                        headers[merged_col - 1] = parent  # Fallback if no child
            else:
                # Single cell header (if not merged)
                if cell.value and cell.value not in ['Comments']:
                    headers[col - 1] = cell.value  # 0-indexed
    
    # Make headers unique
    headers = make_unique(headers)
    
    # Now process rows dynamically for vertical headings and data
    current_parent = None
    current_child = None
    
    for row in range(4, sheet.max_row + 1):
        cell_a = sheet[f'A{row}']
        cell_d = sheet[f'D{row}']  # Check column D for "Restated"
        cell_a_value = cell_a.value
        cell_d_value = cell_d.value
        
        # Skip rows starting with "Forecast based on"
        if cell_a_value and str(cell_a_value).strip().startswith("Forecast based on"):
            continue
        
        # Check if column D contains "Restated" - if yes, treat as data row (not parent)
        has_restated = cell_d_value and str(cell_d_value).strip().lower() == "restated"
        
        # Check if this is a parent row (light blue OR A populated with rest blank)
        # BUT exclude if column D has "Restated"
        is_parent = (is_light_blue(cell_a) or is_parent_row_by_blanks(sheet, row, sheet.max_column)) and not has_restated
        
        if is_parent and cell_a_value and cell_a_value.strip():
            # This is a parent row
            current_parent = cell_a_value.strip()
            current_child = None  # Reset child for new parent
            vertical_headings.append(current_parent)
            row_data = {col: sheet[f'{get_column_letter(col+1)}{row}'].value for col in range(len(headers)) if headers[col]}
            data_rows.append(row_data)
        else:
            # This is a child or grandchild row
            if cell_a_value and cell_a_value.strip():
                if current_child is None:
                    # First level child
                    current_child = cell_a_value.strip()
                    heading = f"{current_parent}_{current_child}"
                else:
                    # Second level (grandchild)
                    grandchild = cell_a_value.strip()
                    heading = f"{current_parent}_{current_child}_{grandchild}"
                vertical_headings.append(heading)
                row_data = {col: sheet[f'{get_column_letter(col+1)}{row}'].value for col in range(len(headers)) if headers[col]}
                data_rows.append(row_data)
    
    # Create DataFrame
    if data_rows and vertical_headings:
        df = pd.DataFrame(data_rows, index=vertical_headings[:len(data_rows)])
        df.columns = headers[:len(df.columns)]  # Trim to match
    else:
        df = pd.DataFrame()  # Empty if no data
    return df

# Streamlit App
st.title("Excel Flattener App")
st.write("Upload an Excel file, select a tab, and download the flattened data.")

uploaded_file = st.file_uploader("Choose an Excel file", type=["xlsx"])

if uploaded_file is not None:
    try:
        # Load workbook with data_only=True to get computed values, not formulas
        wb = openpyxl.load_workbook(uploaded_file, data_only=True)
        sheet_names = wb.sheetnames
        selected_sheet = st.selectbox("Select a tab", sheet_names)
        
        if st.button("Process and Flatten"):
            sheet = wb[selected_sheet]
            flattened_df = process_sheet(sheet)
            
            st.write("Flattened Data Preview:")
            st.dataframe(flattened_df)
            
            # Prepare CSV for download
            csv_buffer = io.StringIO()
            flattened_df.to_csv(csv_buffer)
            csv_data = csv_buffer.getvalue()
            
            st.download_button(
                label="Download Flattened Data as CSV",
                data=csv_data,
                file_name=f"{selected_sheet}_flattened.csv",
                mime="text/csv"
            )
    except Exception as e:
        st.error(f"Error processing file: {str(e)}")
